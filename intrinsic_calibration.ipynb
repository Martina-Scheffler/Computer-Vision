{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut out part of the video\n",
    "#from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "#ffmpeg_extract_subclip(\"./checkerboards/out1F.mp4\", 34, 39, targetname=\"./checkerboards/out1F_cut.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import video \n",
    "cap = cv2.VideoCapture(\"./checkerboards/out1F_cut.mp4\")\n",
    "\n",
    "# get number of frames\n",
    "amount_of_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "start_frame = 0\n",
    "\n",
    "# save frames to array (take them somewhere from the middle of the video)\n",
    "frames = []\n",
    "gray_frames = []\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame);\n",
    "\n",
    "for i in range(start_frame, start_frame + 50):  # use 50 frames\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "         print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "         break\n",
    "     \n",
    "    # convert frame to grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    frames.append(frame)\n",
    "    gray_frames.append(gray_frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() # destroy all opened windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imS = cv2.resize(frames[0], (1280, 720)) \n",
    "cv2.imshow('test', imS)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "False\n",
      "5\n",
      "True\n",
      "6\n",
      "False\n",
      "11\n",
      "True\n",
      "12\n",
      "True\n",
      "13\n",
      "True\n",
      "14\n",
      "True\n",
      "15\n",
      "True\n",
      "16\n",
      "True\n",
      "17\n",
      "True\n",
      "18\n",
      "True\n",
      "19\n",
      "True\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# go through the frames and try to detect a checkerboard in them\n",
    "corners_detected = {}  # frame_id, corners\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)  # todo: choose better params\n",
    "\n",
    "chessboard_width = 5\n",
    "chessboard_height = 7\n",
    "\n",
    "# prepare object points\n",
    "object_points = np.zeros((chessboard_width * chessboard_height, 3), np.float32)\n",
    "object_points[:,:2] = np.mgrid[0:chessboard_height, 0:chessboard_width].T.reshape(-1,2)\n",
    " \n",
    "# Arrays to store object points and image points from all the images.\n",
    "obj_points = [] # 3d point in real world space\n",
    "img_points = [] # 2d points in image plane.\n",
    "\n",
    "i = 0\n",
    "while i < len(gray_frames):\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray_frames[i], (chessboard_height, chessboard_width), None)\n",
    "    \n",
    "    if ret:\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        obj_points.append(object_points)\n",
    "        \n",
    "        corners_refined = cv2.cornerSubPix(gray_frames[i], corners, (11,11), (-1,-1), criteria)  # todo: choose better params\n",
    "        corners_detected[i] = corners_refined\n",
    "        \n",
    "        img_points.append(corners_refined)\n",
    "        \n",
    "        i += 1\n",
    "    else:\n",
    "        i += 5  # skip the next five frames\n",
    "    if len(corners_detected) >= 10:\n",
    "        break\n",
    "\n",
    "print(f'Number of frames where corners were detected: {len(corners_detected)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.drawChessboardCorners(frames[5], (chessboard_height, chessboard_width), corners_detected[5], True)\n",
    "imS = cv2.resize(frames[5], (1280, 720)) \n",
    "cv2.imshow('img', imS)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Matrix: [[5.34198759e+03 0.00000000e+00 1.79078178e+03]\n",
      " [0.00000000e+00 5.11547089e+03 1.18833790e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion: [[-0.35981675  0.56206324 -0.02915499 -0.03313839 -1.28855586]]\n"
     ]
    }
   ],
   "source": [
    "# calibrate camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, gray_frames[0].shape[::-1], None, None)\n",
    "print(f'Camera Matrix: {mtx}')\n",
    "print(f'Distortion: {dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New camera matrix: [[5.07002532e+03 0.00000000e+00 1.69467856e+03]\n",
      " [0.00000000e+00 5.07438613e+03 1.16869786e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undistort an image - first refine camera matrix\n",
    "img = frames[0]\n",
    "h, w = img.shape[:2]\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 0, (w,h))\n",
    "print(f'New camera matrix: {newcameramtx}')\n",
    "\n",
    "# undistort - option 1\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    " \n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst_1 = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('before_undistort.png', frames[0])\n",
    "cv2.imwrite('calibresult-1.png', dst_1)\n",
    "\n",
    "# undistort - option 2\n",
    "mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)\n",
    "dst_2 = cv2.remap(img, mapx, mapy, cv2.INTER_LINEAR)\n",
    " \n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst_2 = dst_2[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult-2.png', dst_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 0.4143807207681351\n"
     ]
    }
   ],
   "source": [
    "# check reprojection error\n",
    "mean_error = 0\n",
    "for i in range(len(obj_points)):\n",
    " imgpoints2, _ = cv2.projectPoints(obj_points[i], rvecs[i], tvecs[i], mtx, dist)\n",
    " error = cv2.norm(img_points[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    " mean_error += error\n",
    " \n",
    "print( \"total error: {}\".format(mean_error/len(obj_points)) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
