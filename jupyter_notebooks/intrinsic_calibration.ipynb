{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = 1\n",
    "extrinsic_time = '00:00:56'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "# import video \n",
    "cap = cv2.VideoCapture(f'../chessboard_videos/out{camera}F.mp4')\n",
    "\n",
    "# get number of frames\n",
    "amount_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "start_frame = 1000\n",
    "\n",
    "# Set the frame skip interval (1 frame every 30)\n",
    "frame_skip = 15\n",
    "\n",
    "# save frames to array \n",
    "frames = []\n",
    "gray_frames = []\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "for i in range(start_frame, amount_of_frames):  \n",
    "    ret, frame = cap.read()\n",
    "    if i % frame_skip == 0:        \n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        \n",
    "        # convert frame to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        frames.append(frame)\n",
    "        gray_frames.append(gray_frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() # destroy all opened windows\n",
    "\n",
    "print(len(gray_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imS = cv2.resize(gray_frames[30], (1280, 720)) \n",
    "# cv2.imshow('test', imS)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True\n",
      "5 True\n",
      "10 True\n",
      "15 True\n",
      "20 True\n",
      "25 True\n",
      "30 True\n",
      "35 True\n",
      "40 False\n",
      "45 False\n",
      "50 True\n",
      "55 True\n",
      "60 True\n",
      "65 True\n",
      "70 True\n",
      "75 True\n",
      "80 True\n",
      "85 True\n",
      "90 True\n",
      "95 True\n",
      "100 True\n",
      "105 True\n",
      "110 True\n",
      "115 True\n",
      "120 True\n",
      "125 True\n",
      "130 True\n",
      "135 True\n",
      "140 True\n",
      "145 True\n",
      "150 True\n",
      "155 True\n",
      "160 True\n",
      "165 True\n",
      "170 True\n",
      "175 True\n",
      "Number of frames where corners were detected: 34\n"
     ]
    }
   ],
   "source": [
    "# go through the frames and try to detect a checkerboard in them\n",
    "corners_detected = {}  # frame_id, corners\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)  # todo: choose better params\n",
    "\n",
    "chessboard_width = 5\n",
    "chessboard_height = 7\n",
    "\n",
    "# prepare object points\n",
    "object_points = np.zeros((chessboard_width * chessboard_height, 3), np.float32)\n",
    "object_points[:,:2] = np.mgrid[0:chessboard_height, 0:chessboard_width].T.reshape(-1,2) \n",
    "\n",
    " \n",
    "# Arrays to store object points and image points from all the images.\n",
    "obj_points = [] # 3d point in real world space\n",
    "img_points = [] # 2d points in image plane.\n",
    "\n",
    "i = 0\n",
    "while i < len(gray_frames):\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray_frames[i], (chessboard_height, chessboard_width), None)\n",
    "    print(i, ret)\n",
    "    \n",
    "    if ret:\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        obj_points.append(object_points)\n",
    "        \n",
    "        corners_refined = cv2.cornerSubPix(gray_frames[i], corners, (11,11), (-1,-1), criteria)  # todo: choose better params\n",
    "        corners_detected[i] = corners_refined\n",
    "        \n",
    "        img_points.append(corners)\n",
    "        \n",
    "        i += 5\n",
    "    else:\n",
    "        i += 5  # skip the next five frames\n",
    "    #if len(corners_detected) >= 50:\n",
    "        #break\n",
    "\n",
    "print(f'Number of frames where corners were detected: {len(corners_detected)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.drawChessboardCorners(frames[10], (chessboard_height, chessboard_width), corners_detected[10], True)\n",
    "# imS = cv2.resize(frames[10], (1280, 720)) \n",
    "# cv2.imshow('img', imS)\n",
    "# cv2.waitKey(0)\n",
    " \n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Matrix: [[2.03425508e+03 0.00000000e+00 1.85906416e+03]\n",
      " [0.00000000e+00 2.05401046e+03 1.12199428e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion: [[-0.30915611  0.09657182  0.0009885   0.00158603 -0.01378949]]\n"
     ]
    }
   ],
   "source": [
    "# calibrate camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, gray_frames[0].shape[::-1], None, None)\n",
    "print(f'Camera Matrix: {mtx}')\n",
    "print(f'Distortion: {dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut out single frame for extrinsic calibration\n",
    "import moviepy.editor as mpy\n",
    "maskclip = mpy.VideoFileClip(f'../videos/out{camera}.mp4')\n",
    "maskclip.save_frame(f'../extrinsic_calibration_images/out{camera}.png', t=extrinsic_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New camera matrix: [[8.12358041e+02 0.00000000e+00 1.77871534e+03]\n",
      " [0.00000000e+00 8.23148286e+02 1.07761494e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# undistort an image - first refine camera matrix\n",
    "img = cv2.imread(f'../extrinsic_calibration_images/out{camera}.png')\n",
    "h, w = img.shape[:2]\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "print(f'New camera matrix: {newcameramtx}')\n",
    "\n",
    "# undistort - option 1\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst_1 = dst[y:y+h, x:x+w]\n",
    "\n",
    "cv2.imwrite(f'../extrinsic_calibration_images/out{camera}_undistorted.png', dst_1)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'../intrinsic_matrices/{camera}_refined', newcameramtx)\n",
    "np.save(f'../intrinsic_matrices/{camera}', mtx)\n",
    "np.save(f'../distortions/{camera}', dist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
